{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def scrape_data(data_path, driver_path, state='archived', headless=True):\n",
    "    \"\"\"\n",
    "    Refresh the json data folders of petition data (petition type dependent).\n",
    "    \n",
    "    Note: The website JSON files contain more attributes than the CSV files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    state       : petition type ['archived'/'closed'/'rejected'/'open']\n",
    "    data_path   : location to save petition json data\n",
    "    driver_path : location of web driver (currently Mozilla)\n",
    "    headless    : whether or not you seen the browser popup\n",
    "    \"\"\"\n",
    "    \n",
    "    # To prevent download dialog\n",
    "    options = Options()\n",
    "    options.set_preference('browser.download.folderList', 2) # custom location\n",
    "    options.set_preference('browser.download.manager.showWhenStarting', False)\n",
    "    options.set_preference('browser.download.dir', data_path)\n",
    "    options.set_preference('browser.helperApps.neverAsk.saveToDisk', 'text/csv')\n",
    "    \n",
    "    # Without pop-up browser window (faster)\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless\")\n",
    "      \n",
    "    #service = Service(driver_path)\n",
    "\n",
    "    #browser = webdriver.Firefox(service=service, options=options)\n",
    "    browser = webdriver.Firefox(options=options)\n",
    "\n",
    "    # Find total number of pages\n",
    "    browser.get(\"https://petition.parliament.uk/petitions?state=all\")\n",
    "    page_count = browser.find_element_by_xpath('/html/body/main/div/div/a/span[2]')\n",
    "    n_pages = int(page_count.text.split(' ')[-1])\n",
    "    \n",
    "    # Loop through pages and scrape petition data\n",
    "    for i in np.arange(0, n_pages + 1, 1):\n",
    "        browser.get(\"https://petition.parliament.uk/petitions?page=\" + str(i) + \"&state=\" + state)\n",
    "\n",
    "        page_tag = browser.find_element_by_xpath('/html/body/main/div/div/a/span[2]').text.replace(\" \", \"_\")\n",
    "\n",
    "        # Move to JSON page\n",
    "        browser.find_element_by_xpath('//*[text() = \"JSON\"]').click()\n",
    "\n",
    "        # Download JSON\n",
    "        data = requests.get(browser.current_url).json()\n",
    "\n",
    "        # Save json to file\n",
    "        with open(data_path + 'data_' + page_tag + '.json', 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "        if i == n_pages:\n",
    "            # Last page has to be saved differently as the button changes\n",
    "            data = requests.get(browser.current_url).json()\n",
    "            page_tag = str(n_pages) + \"of\" + str(n_pages)\n",
    "            # Save json to file\n",
    "            with open(data_path + 'data_' + page_tag + '.json', 'w') as f:\n",
    "                json.dump(data, f)\n",
    "    \n",
    "    browser.close()\n",
    "\n",
    "\n",
    "def setup_folders(data_dir, driver_path, base_directory = 'petitions_website/', state = 'all'):\n",
    "    data_path = os.path.join(data_dir, base_directory)\n",
    "    if not os.path.exists(data_path):\n",
    "        os.mkdir(data_path)\n",
    "    directory = base_directory + state + '/'\n",
    "    data_path = os.path.join(data_dir, directory)\n",
    "    if not os.path.exists(data_path):\n",
    "        os.mkdir(data_path)\n",
    "    return data_path\n",
    "\n",
    "\n",
    "# Parameters\n",
    "state = 'all'\n",
    "data_dir = '/home/will/Datasets/'\n",
    "driver_path = '/home/will/Projects/GovPetitionsUK/gov_uk_petitions_analysis/geckodriver'\n",
    "\n",
    "# Setup folders\n",
    "data_path = setup_folders(data_dir, driver_path, state = state)\n",
    "\n",
    "# Scrape the data\n",
    "scrape_data(data_path, driver_path, state = state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check project folder for downloaded petition data\n",
    "\n",
    "1. Set file paths\n",
    "2. Check downloads folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gov_uk_env",
   "language": "python",
   "name": "gov_uk_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
